POA - LLM From Scratch

03/09
	- Initial version of code 

05/11
	- Small update moving project forward.

05/24
	- Listing 2.3 Implementing a simple text tokenizer 
	- Splits text into tokens and carries out the string-to-integer mapping to produce token IDs via the vocabulary
	- Added invocation in regexExample.py 

05/27
	- Added |unk| and |endoftext| tokens 
	
06/01
	- Cleaned up, split out, and commented source code files
	- Added v2 tokenizer (adds unk and eof tokens) and assoc Run... src file 

06/25
	- Did section 2.5, a more sophisticated tokenization scheme 
		based on a concept called byte pair encoding (BPE)
	- installed and used Tiktoken lib from openai via github)
	
07/05
	- Bought book using 4th of july sale (needed to access appendix A)
	
07/27
	- Updated python version and tiktoken, updated python -> python3 symbolic link
	- Retested tiktoken, tried out various word->token encodings 
	- Updated shortcut in 'Reference:' section below.
	- Renamed source files to ref section and order they were created
		
NEXT: 
	- Before starting anything, check working copy status & pull latest from GitHub
	- Continue at Reference link (below)
		Description: 2.6 Data sampling with a sliding window


Reference:
https://livebook.manning.com/book/build-a-large-language-model-from-scratch/chapter-2/v-8/157


Dependencies: 
TiToken from Since implementing BPE can be relatively complicated, we will use an existing Python open-source library called tiktoken (https://github.com/openai/tiktoken)
Installed via: 
	pip install tiktoken 

After install can verify by checking version.  See my source code file TestTiToken.py


